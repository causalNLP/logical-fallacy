Sender: LSF System <lsfadmin@eu-g3-001>
Subject: Job 212621358: <python remove_content_words.py -p ../../data/climate_train_mh.csv -a source_article -m /cluster/project/sachan/abhinav/saved_models/mpnet> in cluster <euler> Done

Job <python remove_content_words.py -p ../../data/climate_train_mh.csv -a source_article -m /cluster/project/sachan/abhinav/saved_models/mpnet> was submitted from host <eu-login-08> by user <alalwani> in cluster <euler> at Fri Apr  8 12:02:09 2022
Job was executed on host(s) <eu-g3-001>, in queue <gpu.4h>, as user <alalwani> in cluster <euler> at Fri Apr  8 12:02:33 2022
</cluster/home/alalwani> was used as the home directory.
</cluster/home/alalwani/logical-fallacy/codes_for_models/abhinav_experiments> was used as the working directory.
Started at Fri Apr  8 12:02:33 2022
Terminated at Fri Apr  8 12:03:45 2022
Results reported at Fri Apr  8 12:03:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python remove_content_words.py -p ../../data/climate_train_mh.csv -a source_article -m /cluster/project/sachan/abhinav/saved_models/mpnet
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   43.47 sec.
    Max Memory :                                 4412 MB
    Average Memory :                             2366.00 MB
    Total Requested Memory :                     30000.00 MB
    Delta Memory :                               25588.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   70 sec.
    Turnaround time :                            96 sec.

The output (if any) follows:

2022-04-08 12:02:52 INFO: Writing properties to tmp file: corenlp_server-3171a1f60a2540eb.props
Writing properties to tmp file: corenlp_server-3171a1f60a2540eb.props
2022-04-08 12:02:52 INFO: Starting server with command: java -Xmx5G -cp /cluster/home/alalwani/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-3171a1f60a2540eb.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized
Starting server with command: java -Xmx5G -cp /cluster/home/alalwani/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-3171a1f60a2540eb.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized
[main] INFO CoreNLP - --- StanfordCoreNLPServer#main() called ---
[main] INFO CoreNLP - Server default properties:
			(Note: unspecified annotator properties are English defaults)
			annotators = tokenize,ssplit,pos,lemma,ner,parse,depparse,coref
			inputFormat = text
			outputFormat = serialized
			prettyPrint = false
			threads = 5
[main] INFO CoreNLP - Threads: 5
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos
[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [1.2 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].
[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.1 sec].
[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].
[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.
[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580705 unique entries out of 581864 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.
[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4867 unique entries out of 4867 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.
[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585572 unique entries from 2 files
[main] INFO edu.stanford.nlp.pipeline.NERCombinerAnnotator - numeric classifiers: true; SUTime: true [no docDate]; fine grained: true
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [1.3 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse
[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... Time elapsed: 1.4 sec
[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 20000 vectors, elapsed Time: 0.825 sec
[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [2.2 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref
[main] INFO edu.stanford.nlp.coref.statistical.SimpleLinearClassifier - Loading coref model edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz ... done [0.5 sec].
[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency
[main] INFO CoreNLP - Starting server...
[main] WARN CoreNLP - java.net.BindException: Address already in use
  sun.nio.ch.Net.bind0(Native Method)
  sun.nio.ch.Net.bind(Net.java:433)
  sun.nio.ch.Net.bind(Net.java:425)
  sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
  sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
  sun.net.httpserver.ServerImpl.<init>(ServerImpl.java:100)
  sun.net.httpserver.HttpServerImpl.<init>(HttpServerImpl.java:50)
  sun.net.httpserver.DefaultHttpServerProvider.createHttpServer(DefaultHttpServerProvider.java:35)
  com.sun.net.httpserver.HttpServer.create(HttpServer.java:130)
  edu.stanford.nlp.pipeline.StanfordCoreNLPServer.run(StanfordCoreNLPServer.java:1534)
  edu.stanford.nlp.pipeline.StanfordCoreNLPServer.launchServer(StanfordCoreNLPServer.java:1631)
  edu.stanford.nlp.pipeline.StanfordCoreNLPServer.main(StanfordCoreNLPServer.java:1638)
[Thread-0] INFO CoreNLP - CoreNLP Server is shutting down.
/cluster/home/alalwani/logical-fallacy/codes_for_models/abhinav_experiments/remove_content_words.py:201: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn("%s updated to %s", text, ans)
In June last year , a severe heatwave claimed over 1,000 lives in Karachi , Pakistan . Severe drought caused food shortages for millions of people in Ethiopia , with a lack of rainfall resulting in “ intense and widespread ” forest fires in Indonesia that belched out a vast quantity of greenhouse gas .  updated to In June last year , a MSK<0> heatwave claimed over 1,000 lives in MSK<2> , MSK<2> . MSK<0> drought caused food shortages for millions of people in Ethiopia , with a lack of rainfall resulting in MSK<1> intense and widespread MSK<1> forest fires in Indonesia that belched out a vast quantity of greenhouse gas . 
0 0 None False
0 1 None False
0 2 None False
0 3 None False
0 4 None False
0 5 None False
0 6 None False
0 7 None False
0 8 None False
0 9 None False
0 10 None False
0 11 None False
0 12 None False
0 13 None False
0 14 None False
0 15 None False
0 16 None False
1 0 None False
1 1 None False
1 2 None False
1 3 None False
1 4 None False
1 5 None False
1 6 None False
1 7 None False
1 8 None False
1 9 None False
1 10 None False
1 11 None False
1 12 None False
1 13 None False
1 14 None False
1 15 None False
1 16 None False
1 17 None False
1 18 None False
1 19 None False
1 20 None False
1 21 None False
1 22 None False
1 23 None False
1 24 None False
1 25 None False
1 26 None False
1 27 None False
1 28 None False
1 29 None False
1 30 None False
1 31 None False
1 32 None False
1 33 None False
1 34 None False
1 35 None False
1 36 None False
1 37 None False
