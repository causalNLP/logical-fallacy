Sender: LSF System <lsfadmin@eu-g3-060>
Subject: Job 203292899: <python logicclimate.py -t /cluster/project/sachan/abhinav/saved_models/electra-ft -m /cluster/project/sachan/abhinav/saved_models/electra-ft -w 12 -mp base -ts 1 -ds 1> in cluster <euler> Exited

Job <python logicclimate.py -t /cluster/project/sachan/abhinav/saved_models/electra-ft -m /cluster/project/sachan/abhinav/saved_models/electra-ft -w 12 -mp base -ts 1 -ds 1> was submitted from host <eu-login-33> by user <alalwani> in cluster <euler> at Fri Feb  4 10:52:43 2022
Job was executed on host(s) <eu-g3-060>, in queue <gpuhe.4h>, as user <alalwani> in cluster <euler> at Fri Feb  4 10:53:22 2022
</cluster/home/alalwani> was used as the home directory.
</cluster/home/alalwani/logical-fallacy/codes_for_models/abhinav_experiments> was used as the working directory.
Started at Fri Feb  4 10:53:22 2022
Terminated at Fri Feb  4 10:53:55 2022
Results reported at Fri Feb  4 10:53:55 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python logicclimate.py -t /cluster/project/sachan/abhinav/saved_models/electra-ft -m /cluster/project/sachan/abhinav/saved_models/electra-ft -w 12 -mp base -ts 1 -ds 1
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   10.02 sec.
    Max Memory :                                 6410 MB
    Average Memory :                             256.00 MB
    Total Requested Memory :                     30000.00 MB
    Delta Memory :                               23590.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   43 sec.
    Turnaround time :                            72 sec.

The output (if any) follows:

device = cuda
Namespace(tokenizer='/cluster/project/sachan/abhinav/saved_models/electra-ft', model='/cluster/project/sachan/abhinav/saved_models/electra-ft', weight='12', savepath=None, map='base', train_strat='1', dev_strat='1', finetune='F')
initializing model
creating dataset
Traceback (most recent call last):
  File "/cluster/home/alalwani/logical-fallacy/codes_for_models/abhinav_experiments/logicclimate.py", line 37, in <module>
    fallacy_ds = MNLIDataset(args.tokenizer, fallacy_train, fallacy_dev, 'logical_fallacies', args.map, fallacy_test,
  File "/cluster/home/alalwani/logical-fallacy/codes_for_models/abhinav_experiments/logicedu.py", line 70, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, do_lower_case=True)
  File "/cluster/home/alalwani/miniconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py", line 549, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/cluster/home/alalwani/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 1733, in from_pretrained
    raise EnvironmentError(msg)
OSError: Can't load tokenizer for '/cluster/project/sachan/abhinav/saved_models/electra-ft'. Make sure that:

- '/cluster/project/sachan/abhinav/saved_models/electra-ft' is a correct model identifier listed on 'https://huggingface.co/models'
  (make sure '/cluster/project/sachan/abhinav/saved_models/electra-ft' is not a path to a local directory with something else, in that case)

- or '/cluster/project/sachan/abhinav/saved_models/electra-ft' is the correct path to a directory containing relevant tokenizer files


